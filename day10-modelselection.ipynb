{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "# 学習器\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# model_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8)\n",
    "clf = RandomForestClassifier()\n",
    "# clf = GaussianNB()\n",
    "# clf = LogisticRegression()\n",
    "pred_y = clf.fit(X_train, y_train).predict(X_test)\n",
    "a = metrics.classification_report(y_test, pred_y)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最も簡単なCVの方法\n",
    "`cross_val_score(clf, data, target, cv=5, scoring=\"accuracy\")`\n",
    "\n",
    "|変数|役割|\n",
    "|---|---|\n",
    "|clf|学習器|\n",
    "|data|データ|\n",
    "|target|ラベル|\n",
    "|cv|クロスバリデーションの回数|\n",
    "|scoring|評価する指標[(参照:metrics)](http://scikit-learn.org/stable/modules/model_evaluation.html)|\n",
    "\n",
    "scoringに適用できるもの:\n",
    "```python\n",
    "['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing cross-validated metrics\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "digits = load_digits()\n",
    "clf = RandomForestClassifier()\n",
    "scoring = \"f1_macro\"\n",
    "scores = cross_val_score(clf, digits.data, digits.target, cv=5, scoring=scoring)\n",
    "print(\"{}:{:.3f}+/-{:.3f}\".format(scoring, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## わき道 : pipline\n",
    "`sklearn.pipeline`を使うと、処理が簡潔に書ける。[(参考)](http://scikit-learn.org/stable/modules/pipeline.html#combining-estimators)\n",
    "\n",
    "例 : 正規化した後の効果をcross_validationしたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通常\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "print(clf.score(X_test_transformed, y_test))\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# 処理を流す順に関数を書いていく\n",
    "scoring = \"f1_macro\"\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), SVC(kernel=\"linear\",C=1))\n",
    "scores = cross_val_score(clf, digits.data, digits.target, cv=5, scoring=scoring)\n",
    "print(\"{}:{:.3f}+/-{:.3f}\".format(scoring, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_validate 関数\n",
    "さっきまでのが`cross_val_scores`関数。ややこしいが少し違う\n",
    "\n",
    "- 評価に**複数の指標**を考慮できる\n",
    "- テストスコアに加えて、**学習の時のスコア、学習時間、テストの時間**などを算出してくれる。\n",
    "\n",
    "つまり、より強力なcross_validationを行える。\n",
    "\n",
    "※0.19.1では、windowsでなぜか動かない。ubuntu14.04では動いた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "scoring = [\"f1_macro\", \"recall_macro\"]\n",
    "clf = SVC(C=1)\n",
    "scores = cross_validate(clf, digits.data, digits.target, scoring=scoring, cv=5)\n",
    "for key,value in scores.items():\n",
    "    print(\"{}:{:.2f}+/-{:.2f}\".format(key, value.mean(), value.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果としてのcross validation\n",
    "test, trainに分けることなく結果の検証ができる関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "clf = RandomForestClassifier()\n",
    "predicted = cross_val_predict(clf, X, y, cv=5)\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterators\n",
    "CrossValidationを行うときの、データセットの分け方\n",
    "- i.i.d data\n",
    "    - K-fold\n",
    "    - Repeated K-Fold\n",
    "    - Leave One Out (LOO)\n",
    "    - Leave P out (LPO)\n",
    "    - Shuffle & Split\n",
    "- iterators with stratification based on class labels(サンプリングとか)\n",
    "    - Stratified k-fold\n",
    "    - Stratified Shuffle Split\n",
    "- Grouped data　i.i.dデータと基本おなじ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# iterator\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# from sklearn.model_selection import LeavePOut\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "# leave-one-out 交差検定\n",
    "iterater = KFold(n_splits=5)\n",
    "results = []\n",
    "for train_indexes, test_indexes in iterater.split(digits.data):\n",
    "#     print(train_indexes, test_indexes)\n",
    "    X = digits.data[train_indexes]\n",
    "    y = digits.target[train_indexes]\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X,y)\n",
    "    pred_y = clf.predict(digits.data[test_indexes])\n",
    "    ac = accuracy_score(digits.target[test_indexes], pred_y)\n",
    "    results.append(ac)\n",
    "results = np.array(results)\n",
    "print(\"KFold accuracy: {:.2f}+/-{:.2f}\".format(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータを調整する\n",
    "[Tuning the hyper-parameters of an estimator](http://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "- グリッドサーチ\n",
    "- ランダム選択\n",
    "- モデルに合わせた賢いCV\n",
    "\n",
    "\n",
    "他変数最適化の問題として、ある指標を評価関数にして解くというのもよさそう。自分で関数をつくらなきゃだけど。\n",
    "- Gaussian Process Optimization\n",
    "- PSO, CMA-ES など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "clf.get_params()\n",
    "svc = SVC()\n",
    "scoring = \"accuracy\"\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': [0.001, 0.0001]},\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.001, 0.0001]}\n",
    "    ]\n",
    "clf = GridSearchCV(svc, param_grid,cv=4)\n",
    "clf.fit(digits.data, digits.target)\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df_scored = df.sort_values(by=[\"rank_test_score\"])[[\"params\",\"mean_test_score\",\"std_test_score\",\"mean_fit_time\"]]\n",
    "df_scored.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
